{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "---------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(299),\n",
    "        transforms.CenterCrop(299),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(299),\n",
    "        transforms.CenterCrop(299),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model\n",
    "------------------\n",
    "\n",
    "Now, let's write a general function to train a model. Here, we will\n",
    "illustrate:\n",
    "\n",
    "-  Scheduling the learning rate\n",
    "-  Saving the best model\n",
    "\n",
    "In the following, parameter ``scheduler`` is an LR scheduler object from\n",
    "``torch.optim.lr_scheduler``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, writer=None, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    \n",
    "                    if isinstance(outputs, tuple):\n",
    "                        outputs=outputs[0]\n",
    "                    \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "\n",
    "            writer.add_scalar(phase+\"/loss\", epoch_loss, epoch)\n",
    "            writer.add_scalar(phase+\"/acc\", epoch_acc, epoch)\n",
    "\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuning the convnet\n",
    "----------------------\n",
    "\n",
    "Load a pretrained model and reset final fully connected layer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_ft = models.inception_v3(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=6, gamma=0.1)\n",
    "\n",
    "writer = SummaryWriter('./logs/inception_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/39\n",
      "----------\n",
      "train Loss: 1.2343 Acc: 0.5450\n",
      "val Loss: 0.5817 Acc: 0.7935\n",
      "\n",
      "Epoch 1/39\n",
      "----------\n",
      "train Loss: 0.6461 Acc: 0.7807\n",
      "val Loss: 0.3549 Acc: 0.8947\n",
      "\n",
      "Epoch 2/39\n",
      "----------\n",
      "train Loss: 0.4236 Acc: 0.8581\n",
      "val Loss: 0.2727 Acc: 0.9028\n",
      "\n",
      "Epoch 3/39\n",
      "----------\n",
      "train Loss: 0.2893 Acc: 0.9056\n",
      "val Loss: 0.2477 Acc: 0.9069\n",
      "\n",
      "Epoch 4/39\n",
      "----------\n",
      "train Loss: 0.2188 Acc: 0.9260\n",
      "val Loss: 0.2002 Acc: 0.9433\n",
      "\n",
      "Epoch 5/39\n",
      "----------\n",
      "train Loss: 0.1774 Acc: 0.9450\n",
      "val Loss: 0.1601 Acc: 0.9474\n",
      "\n",
      "Epoch 6/39\n",
      "----------\n",
      "train Loss: 0.0797 Acc: 0.9759\n",
      "val Loss: 0.1091 Acc: 0.9676\n",
      "\n",
      "Epoch 7/39\n",
      "----------\n",
      "train Loss: 0.0595 Acc: 0.9837\n",
      "val Loss: 0.1215 Acc: 0.9676\n",
      "\n",
      "Epoch 8/39\n",
      "----------\n",
      "train Loss: 0.0541 Acc: 0.9843\n",
      "val Loss: 0.1004 Acc: 0.9717\n",
      "\n",
      "Epoch 9/39\n",
      "----------\n",
      "train Loss: 0.0459 Acc: 0.9871\n",
      "val Loss: 0.0987 Acc: 0.9676\n",
      "\n",
      "Epoch 10/39\n",
      "----------\n",
      "train Loss: 0.0334 Acc: 0.9927\n",
      "val Loss: 0.1175 Acc: 0.9676\n",
      "\n",
      "Epoch 11/39\n",
      "----------\n",
      "train Loss: 0.0313 Acc: 0.9912\n",
      "val Loss: 0.1082 Acc: 0.9676\n",
      "\n",
      "Epoch 12/39\n",
      "----------\n",
      "train Loss: 0.0287 Acc: 0.9931\n",
      "val Loss: 0.0985 Acc: 0.9676\n",
      "\n",
      "Epoch 13/39\n",
      "----------\n",
      "train Loss: 0.0287 Acc: 0.9918\n",
      "val Loss: 0.1009 Acc: 0.9676\n",
      "\n",
      "Epoch 14/39\n",
      "----------\n",
      "train Loss: 0.0265 Acc: 0.9942\n",
      "val Loss: 0.1058 Acc: 0.9636\n",
      "\n",
      "Epoch 15/39\n",
      "----------\n",
      "train Loss: 0.0234 Acc: 0.9951\n",
      "val Loss: 0.0987 Acc: 0.9757\n",
      "\n",
      "Epoch 16/39\n",
      "----------\n",
      "train Loss: 0.0233 Acc: 0.9948\n",
      "val Loss: 0.0953 Acc: 0.9717\n",
      "\n",
      "Epoch 17/39\n",
      "----------\n",
      "train Loss: 0.0277 Acc: 0.9942\n",
      "val Loss: 0.1041 Acc: 0.9717\n",
      "\n",
      "Epoch 18/39\n",
      "----------\n",
      "train Loss: 0.0237 Acc: 0.9951\n",
      "val Loss: 0.0938 Acc: 0.9717\n",
      "\n",
      "Epoch 19/39\n",
      "----------\n",
      "train Loss: 0.0225 Acc: 0.9948\n",
      "val Loss: 0.1013 Acc: 0.9676\n",
      "\n",
      "Epoch 20/39\n",
      "----------\n",
      "train Loss: 0.0258 Acc: 0.9942\n",
      "val Loss: 0.1009 Acc: 0.9717\n",
      "\n",
      "Epoch 21/39\n",
      "----------\n",
      "train Loss: 0.0259 Acc: 0.9935\n",
      "val Loss: 0.1030 Acc: 0.9676\n",
      "\n",
      "Epoch 22/39\n",
      "----------\n",
      "train Loss: 0.0256 Acc: 0.9951\n",
      "val Loss: 0.0946 Acc: 0.9717\n",
      "\n",
      "Epoch 23/39\n",
      "----------\n",
      "train Loss: 0.0301 Acc: 0.9923\n",
      "val Loss: 0.1056 Acc: 0.9717\n",
      "\n",
      "Epoch 24/39\n",
      "----------\n",
      "train Loss: 0.0275 Acc: 0.9931\n",
      "val Loss: 0.1023 Acc: 0.9717\n",
      "\n",
      "Epoch 25/39\n",
      "----------\n",
      "train Loss: 0.0256 Acc: 0.9933\n",
      "val Loss: 0.0979 Acc: 0.9717\n",
      "\n",
      "Epoch 26/39\n",
      "----------\n",
      "train Loss: 0.0232 Acc: 0.9955\n",
      "val Loss: 0.1058 Acc: 0.9676\n",
      "\n",
      "Epoch 27/39\n",
      "----------\n",
      "train Loss: 0.0236 Acc: 0.9955\n",
      "val Loss: 0.0996 Acc: 0.9676\n",
      "\n",
      "Epoch 28/39\n",
      "----------\n",
      "train Loss: 0.0225 Acc: 0.9957\n",
      "val Loss: 0.0973 Acc: 0.9717\n",
      "\n",
      "Epoch 29/39\n",
      "----------\n",
      "train Loss: 0.0261 Acc: 0.9942\n",
      "val Loss: 0.1011 Acc: 0.9717\n",
      "\n",
      "Epoch 30/39\n",
      "----------\n",
      "train Loss: 0.0239 Acc: 0.9946\n",
      "val Loss: 0.0953 Acc: 0.9717\n",
      "\n",
      "Epoch 31/39\n",
      "----------\n",
      "train Loss: 0.0264 Acc: 0.9938\n",
      "val Loss: 0.0925 Acc: 0.9717\n",
      "\n",
      "Epoch 32/39\n",
      "----------\n",
      "train Loss: 0.0215 Acc: 0.9953\n",
      "val Loss: 0.1197 Acc: 0.9636\n",
      "\n",
      "Epoch 33/39\n",
      "----------\n",
      "train Loss: 0.0238 Acc: 0.9940\n",
      "val Loss: 0.1018 Acc: 0.9717\n",
      "\n",
      "Epoch 34/39\n",
      "----------\n",
      "train Loss: 0.0244 Acc: 0.9951\n",
      "val Loss: 0.0930 Acc: 0.9717\n",
      "\n",
      "Epoch 35/39\n",
      "----------\n",
      "train Loss: 0.0264 Acc: 0.9944\n",
      "val Loss: 0.0949 Acc: 0.9717\n",
      "\n",
      "Epoch 36/39\n",
      "----------\n",
      "train Loss: 0.0237 Acc: 0.9946\n",
      "val Loss: 0.1039 Acc: 0.9636\n",
      "\n",
      "Epoch 37/39\n",
      "----------\n",
      "train Loss: 0.0202 Acc: 0.9966\n",
      "val Loss: 0.1002 Acc: 0.9636\n",
      "\n",
      "Epoch 38/39\n",
      "----------\n",
      "train Loss: 0.0225 Acc: 0.9944\n",
      "val Loss: 0.0923 Acc: 0.9717\n",
      "\n",
      "Epoch 39/39\n",
      "----------\n",
      "train Loss: 0.0253 Acc: 0.9940\n",
      "val Loss: 0.0917 Acc: 0.9717\n",
      "\n",
      "Training complete in 103m 33s\n",
      "Best val Acc: 0.975709\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, writer,\n",
    "                       num_epochs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze first few layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv.weight False\n",
      "bn.weight False\n",
      "bn.bias False\n",
      "conv.weight False\n",
      "bn.weight False\n",
      "bn.bias False\n",
      "conv.weight False\n",
      "bn.weight False\n",
      "bn.bias False\n",
      "conv.weight False\n",
      "bn.weight False\n",
      "bn.bias False\n",
      "conv.weight False\n",
      "bn.weight False\n",
      "bn.bias False\n",
      "branch1x1.conv.weight True\n",
      "branch1x1.bn.weight True\n",
      "branch1x1.bn.bias True\n",
      "branch5x5_1.conv.weight True\n",
      "branch5x5_1.bn.weight True\n",
      "branch5x5_1.bn.bias True\n",
      "branch5x5_2.conv.weight True\n",
      "branch5x5_2.bn.weight True\n",
      "branch5x5_2.bn.bias True\n",
      "branch3x3dbl_1.conv.weight True\n",
      "branch3x3dbl_1.bn.weight True\n",
      "branch3x3dbl_1.bn.bias True\n",
      "branch3x3dbl_2.conv.weight True\n",
      "branch3x3dbl_2.bn.weight True\n",
      "branch3x3dbl_2.bn.bias True\n",
      "branch3x3dbl_3.conv.weight True\n",
      "branch3x3dbl_3.bn.weight True\n",
      "branch3x3dbl_3.bn.bias True\n",
      "branch_pool.conv.weight True\n",
      "branch_pool.bn.weight True\n",
      "branch_pool.bn.bias True\n",
      "branch1x1.conv.weight True\n",
      "branch1x1.bn.weight True\n",
      "branch1x1.bn.bias True\n",
      "branch5x5_1.conv.weight True\n",
      "branch5x5_1.bn.weight True\n",
      "branch5x5_1.bn.bias True\n",
      "branch5x5_2.conv.weight True\n",
      "branch5x5_2.bn.weight True\n",
      "branch5x5_2.bn.bias True\n",
      "branch3x3dbl_1.conv.weight True\n",
      "branch3x3dbl_1.bn.weight True\n",
      "branch3x3dbl_1.bn.bias True\n",
      "branch3x3dbl_2.conv.weight True\n",
      "branch3x3dbl_2.bn.weight True\n",
      "branch3x3dbl_2.bn.bias True\n",
      "branch3x3dbl_3.conv.weight True\n",
      "branch3x3dbl_3.bn.weight True\n",
      "branch3x3dbl_3.bn.bias True\n",
      "branch_pool.conv.weight True\n",
      "branch_pool.bn.weight True\n",
      "branch_pool.bn.bias True\n",
      "branch1x1.conv.weight True\n",
      "branch1x1.bn.weight True\n",
      "branch1x1.bn.bias True\n",
      "branch5x5_1.conv.weight True\n",
      "branch5x5_1.bn.weight True\n",
      "branch5x5_1.bn.bias True\n",
      "branch5x5_2.conv.weight True\n",
      "branch5x5_2.bn.weight True\n",
      "branch5x5_2.bn.bias True\n",
      "branch3x3dbl_1.conv.weight True\n",
      "branch3x3dbl_1.bn.weight True\n",
      "branch3x3dbl_1.bn.bias True\n",
      "branch3x3dbl_2.conv.weight True\n",
      "branch3x3dbl_2.bn.weight True\n",
      "branch3x3dbl_2.bn.bias True\n",
      "branch3x3dbl_3.conv.weight True\n",
      "branch3x3dbl_3.bn.weight True\n",
      "branch3x3dbl_3.bn.bias True\n",
      "branch_pool.conv.weight True\n",
      "branch_pool.bn.weight True\n",
      "branch_pool.bn.bias True\n",
      "branch3x3.conv.weight True\n",
      "branch3x3.bn.weight True\n",
      "branch3x3.bn.bias True\n",
      "branch3x3dbl_1.conv.weight True\n",
      "branch3x3dbl_1.bn.weight True\n",
      "branch3x3dbl_1.bn.bias True\n",
      "branch3x3dbl_2.conv.weight True\n",
      "branch3x3dbl_2.bn.weight True\n",
      "branch3x3dbl_2.bn.bias True\n",
      "branch3x3dbl_3.conv.weight True\n",
      "branch3x3dbl_3.bn.weight True\n",
      "branch3x3dbl_3.bn.bias True\n",
      "branch1x1.conv.weight True\n",
      "branch1x1.bn.weight True\n",
      "branch1x1.bn.bias True\n",
      "branch7x7_1.conv.weight True\n",
      "branch7x7_1.bn.weight True\n",
      "branch7x7_1.bn.bias True\n",
      "branch7x7_2.conv.weight True\n",
      "branch7x7_2.bn.weight True\n",
      "branch7x7_2.bn.bias True\n",
      "branch7x7_3.conv.weight True\n",
      "branch7x7_3.bn.weight True\n",
      "branch7x7_3.bn.bias True\n",
      "branch7x7dbl_1.conv.weight True\n",
      "branch7x7dbl_1.bn.weight True\n",
      "branch7x7dbl_1.bn.bias True\n",
      "branch7x7dbl_2.conv.weight True\n",
      "branch7x7dbl_2.bn.weight True\n",
      "branch7x7dbl_2.bn.bias True\n",
      "branch7x7dbl_3.conv.weight True\n",
      "branch7x7dbl_3.bn.weight True\n",
      "branch7x7dbl_3.bn.bias True\n",
      "branch7x7dbl_4.conv.weight True\n",
      "branch7x7dbl_4.bn.weight True\n",
      "branch7x7dbl_4.bn.bias True\n",
      "branch7x7dbl_5.conv.weight True\n",
      "branch7x7dbl_5.bn.weight True\n",
      "branch7x7dbl_5.bn.bias True\n",
      "branch_pool.conv.weight True\n",
      "branch_pool.bn.weight True\n",
      "branch_pool.bn.bias True\n",
      "branch1x1.conv.weight True\n",
      "branch1x1.bn.weight True\n",
      "branch1x1.bn.bias True\n",
      "branch7x7_1.conv.weight True\n",
      "branch7x7_1.bn.weight True\n",
      "branch7x7_1.bn.bias True\n",
      "branch7x7_2.conv.weight True\n",
      "branch7x7_2.bn.weight True\n",
      "branch7x7_2.bn.bias True\n",
      "branch7x7_3.conv.weight True\n",
      "branch7x7_3.bn.weight True\n",
      "branch7x7_3.bn.bias True\n",
      "branch7x7dbl_1.conv.weight True\n",
      "branch7x7dbl_1.bn.weight True\n",
      "branch7x7dbl_1.bn.bias True\n",
      "branch7x7dbl_2.conv.weight True\n",
      "branch7x7dbl_2.bn.weight True\n",
      "branch7x7dbl_2.bn.bias True\n",
      "branch7x7dbl_3.conv.weight True\n",
      "branch7x7dbl_3.bn.weight True\n",
      "branch7x7dbl_3.bn.bias True\n",
      "branch7x7dbl_4.conv.weight True\n",
      "branch7x7dbl_4.bn.weight True\n",
      "branch7x7dbl_4.bn.bias True\n",
      "branch7x7dbl_5.conv.weight True\n",
      "branch7x7dbl_5.bn.weight True\n",
      "branch7x7dbl_5.bn.bias True\n",
      "branch_pool.conv.weight True\n",
      "branch_pool.bn.weight True\n",
      "branch_pool.bn.bias True\n",
      "branch1x1.conv.weight True\n",
      "branch1x1.bn.weight True\n",
      "branch1x1.bn.bias True\n",
      "branch7x7_1.conv.weight True\n",
      "branch7x7_1.bn.weight True\n",
      "branch7x7_1.bn.bias True\n",
      "branch7x7_2.conv.weight True\n",
      "branch7x7_2.bn.weight True\n",
      "branch7x7_2.bn.bias True\n",
      "branch7x7_3.conv.weight True\n",
      "branch7x7_3.bn.weight True\n",
      "branch7x7_3.bn.bias True\n",
      "branch7x7dbl_1.conv.weight True\n",
      "branch7x7dbl_1.bn.weight True\n",
      "branch7x7dbl_1.bn.bias True\n",
      "branch7x7dbl_2.conv.weight True\n",
      "branch7x7dbl_2.bn.weight True\n",
      "branch7x7dbl_2.bn.bias True\n",
      "branch7x7dbl_3.conv.weight True\n",
      "branch7x7dbl_3.bn.weight True\n",
      "branch7x7dbl_3.bn.bias True\n",
      "branch7x7dbl_4.conv.weight True\n",
      "branch7x7dbl_4.bn.weight True\n",
      "branch7x7dbl_4.bn.bias True\n",
      "branch7x7dbl_5.conv.weight True\n",
      "branch7x7dbl_5.bn.weight True\n",
      "branch7x7dbl_5.bn.bias True\n",
      "branch_pool.conv.weight True\n",
      "branch_pool.bn.weight True\n",
      "branch_pool.bn.bias True\n",
      "branch1x1.conv.weight True\n",
      "branch1x1.bn.weight True\n",
      "branch1x1.bn.bias True\n",
      "branch7x7_1.conv.weight True\n",
      "branch7x7_1.bn.weight True\n",
      "branch7x7_1.bn.bias True\n",
      "branch7x7_2.conv.weight True\n",
      "branch7x7_2.bn.weight True\n",
      "branch7x7_2.bn.bias True\n",
      "branch7x7_3.conv.weight True\n",
      "branch7x7_3.bn.weight True\n",
      "branch7x7_3.bn.bias True\n",
      "branch7x7dbl_1.conv.weight True\n",
      "branch7x7dbl_1.bn.weight True\n",
      "branch7x7dbl_1.bn.bias True\n",
      "branch7x7dbl_2.conv.weight True\n",
      "branch7x7dbl_2.bn.weight True\n",
      "branch7x7dbl_2.bn.bias True\n",
      "branch7x7dbl_3.conv.weight True\n",
      "branch7x7dbl_3.bn.weight True\n",
      "branch7x7dbl_3.bn.bias True\n",
      "branch7x7dbl_4.conv.weight True\n",
      "branch7x7dbl_4.bn.weight True\n",
      "branch7x7dbl_4.bn.bias True\n",
      "branch7x7dbl_5.conv.weight True\n",
      "branch7x7dbl_5.bn.weight True\n",
      "branch7x7dbl_5.bn.bias True\n",
      "branch_pool.conv.weight True\n",
      "branch_pool.bn.weight True\n",
      "branch_pool.bn.bias True\n",
      "conv0.conv.weight True\n",
      "conv0.bn.weight True\n",
      "conv0.bn.bias True\n",
      "conv1.conv.weight True\n",
      "conv1.bn.weight True\n",
      "conv1.bn.bias True\n",
      "fc.weight True\n",
      "fc.bias True\n",
      "branch3x3_1.conv.weight True\n",
      "branch3x3_1.bn.weight True\n",
      "branch3x3_1.bn.bias True\n",
      "branch3x3_2.conv.weight True\n",
      "branch3x3_2.bn.weight True\n",
      "branch3x3_2.bn.bias True\n",
      "branch7x7x3_1.conv.weight True\n",
      "branch7x7x3_1.bn.weight True\n",
      "branch7x7x3_1.bn.bias True\n",
      "branch7x7x3_2.conv.weight True\n",
      "branch7x7x3_2.bn.weight True\n",
      "branch7x7x3_2.bn.bias True\n",
      "branch7x7x3_3.conv.weight True\n",
      "branch7x7x3_3.bn.weight True\n",
      "branch7x7x3_3.bn.bias True\n",
      "branch7x7x3_4.conv.weight True\n",
      "branch7x7x3_4.bn.weight True\n",
      "branch7x7x3_4.bn.bias True\n",
      "branch1x1.conv.weight True\n",
      "branch1x1.bn.weight True\n",
      "branch1x1.bn.bias True\n",
      "branch3x3_1.conv.weight True\n",
      "branch3x3_1.bn.weight True\n",
      "branch3x3_1.bn.bias True\n",
      "branch3x3_2a.conv.weight True\n",
      "branch3x3_2a.bn.weight True\n",
      "branch3x3_2a.bn.bias True\n",
      "branch3x3_2b.conv.weight True\n",
      "branch3x3_2b.bn.weight True\n",
      "branch3x3_2b.bn.bias True\n",
      "branch3x3dbl_1.conv.weight True\n",
      "branch3x3dbl_1.bn.weight True\n",
      "branch3x3dbl_1.bn.bias True\n",
      "branch3x3dbl_2.conv.weight True\n",
      "branch3x3dbl_2.bn.weight True\n",
      "branch3x3dbl_2.bn.bias True\n",
      "branch3x3dbl_3a.conv.weight True\n",
      "branch3x3dbl_3a.bn.weight True\n",
      "branch3x3dbl_3a.bn.bias True\n",
      "branch3x3dbl_3b.conv.weight True\n",
      "branch3x3dbl_3b.bn.weight True\n",
      "branch3x3dbl_3b.bn.bias True\n",
      "branch_pool.conv.weight True\n",
      "branch_pool.bn.weight True\n",
      "branch_pool.bn.bias True\n",
      "branch1x1.conv.weight True\n",
      "branch1x1.bn.weight True\n",
      "branch1x1.bn.bias True\n",
      "branch3x3_1.conv.weight True\n",
      "branch3x3_1.bn.weight True\n",
      "branch3x3_1.bn.bias True\n",
      "branch3x3_2a.conv.weight True\n",
      "branch3x3_2a.bn.weight True\n",
      "branch3x3_2a.bn.bias True\n",
      "branch3x3_2b.conv.weight True\n",
      "branch3x3_2b.bn.weight True\n",
      "branch3x3_2b.bn.bias True\n",
      "branch3x3dbl_1.conv.weight True\n",
      "branch3x3dbl_1.bn.weight True\n",
      "branch3x3dbl_1.bn.bias True\n",
      "branch3x3dbl_2.conv.weight True\n",
      "branch3x3dbl_2.bn.weight True\n",
      "branch3x3dbl_2.bn.bias True\n",
      "branch3x3dbl_3a.conv.weight True\n",
      "branch3x3dbl_3a.bn.weight True\n",
      "branch3x3dbl_3a.bn.bias True\n",
      "branch3x3dbl_3b.conv.weight True\n",
      "branch3x3dbl_3b.bn.weight True\n",
      "branch3x3dbl_3b.bn.bias True\n",
      "branch_pool.conv.weight True\n",
      "branch_pool.bn.weight True\n",
      "branch_pool.bn.bias True\n",
      "weight True\n",
      "bias True\n"
     ]
    }
   ],
   "source": [
    "model_conv = torchvision.models.inception_v3(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "# Stage-2 , Freeze all the layers till \"Conv2d_4a_3*3\"\n",
    "ct = []\n",
    "for name, child in model_conv.named_children():\n",
    "    if \"Conv2d_4a_3x3\" in ct:\n",
    "        for params in child.parameters():\n",
    "            params.requires_grad = True\n",
    "    ct.append(name)\n",
    "    \n",
    "# To view which layers are freeze and which layers are not freezed:\n",
    "for name, child in model_conv.named_children():\n",
    "    for name_2, params in child.named_parameters():\n",
    "        print(name_2, params.requires_grad)\n",
    "\n",
    "\n",
    "optimizer_conv = optim.SGD(list(filter(lambda p: p.requires_grad, model_conv.parameters())), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 6 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=6, gamma=0.1)\n",
    "\n",
    "writer = SummaryWriter('./logs/inception_freezed_first4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 1.1482 Acc: 0.5653\n",
      "val Loss: 0.7919 Acc: 0.7490\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 0.5498 Acc: 0.8155\n",
      "val Loss: 0.4549 Acc: 0.8381\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 0.3617 Acc: 0.8807\n",
      "val Loss: 0.2834 Acc: 0.9150\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 0.2574 Acc: 0.9174\n",
      "val Loss: 0.2528 Acc: 0.9190\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 0.1898 Acc: 0.9385\n",
      "val Loss: 0.2108 Acc: 0.9150\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 0.1426 Acc: 0.9568\n",
      "val Loss: 0.2350 Acc: 0.9312\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 0.0763 Acc: 0.9789\n",
      "val Loss: 0.1560 Acc: 0.9514\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 0.0539 Acc: 0.9875\n",
      "val Loss: 0.1657 Acc: 0.9514\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 0.0462 Acc: 0.9877\n",
      "val Loss: 0.1712 Acc: 0.9474\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 0.0348 Acc: 0.9929\n",
      "val Loss: 0.1785 Acc: 0.9514\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 0.0352 Acc: 0.9910\n",
      "val Loss: 0.1609 Acc: 0.9514\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 0.0272 Acc: 0.9942\n",
      "val Loss: 0.1744 Acc: 0.9555\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 0.0215 Acc: 0.9963\n",
      "val Loss: 0.1571 Acc: 0.9514\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 0.0256 Acc: 0.9935\n",
      "val Loss: 0.1503 Acc: 0.9514\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 0.0264 Acc: 0.9925\n",
      "val Loss: 0.1760 Acc: 0.9514\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 0.0253 Acc: 0.9929\n",
      "val Loss: 0.1555 Acc: 0.9555\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 0.0224 Acc: 0.9955\n",
      "val Loss: 0.1664 Acc: 0.9474\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 0.0212 Acc: 0.9961\n",
      "val Loss: 0.1627 Acc: 0.9555\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 0.0244 Acc: 0.9948\n",
      "val Loss: 0.1718 Acc: 0.9514\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 0.0247 Acc: 0.9933\n",
      "val Loss: 0.1502 Acc: 0.9514\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 0.0193 Acc: 0.9961\n",
      "val Loss: 0.1778 Acc: 0.9514\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 0.0216 Acc: 0.9959\n",
      "val Loss: 0.1660 Acc: 0.9514\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 0.0233 Acc: 0.9953\n",
      "val Loss: 0.1494 Acc: 0.9555\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 0.0251 Acc: 0.9935\n",
      "val Loss: 0.1570 Acc: 0.9555\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 0.0249 Acc: 0.9940\n",
      "val Loss: 0.1649 Acc: 0.9514\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 0.0220 Acc: 0.9942\n",
      "val Loss: 0.1639 Acc: 0.9555\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 0.0224 Acc: 0.9942\n",
      "val Loss: 0.1746 Acc: 0.9514\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 0.0239 Acc: 0.9953\n",
      "val Loss: 0.1528 Acc: 0.9514\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 0.0218 Acc: 0.9944\n",
      "val Loss: 0.1549 Acc: 0.9595\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 0.0270 Acc: 0.9931\n",
      "val Loss: 0.1632 Acc: 0.9433\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9946\n",
      "val Loss: 0.1546 Acc: 0.9555\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 0.0235 Acc: 0.9942\n",
      "val Loss: 0.1621 Acc: 0.9555\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 0.0228 Acc: 0.9946\n",
      "val Loss: 0.1557 Acc: 0.9514\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 0.0275 Acc: 0.9942\n",
      "val Loss: 0.1901 Acc: 0.9555\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 0.0256 Acc: 0.9944\n",
      "val Loss: 0.1439 Acc: 0.9555\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 0.0196 Acc: 0.9961\n",
      "val Loss: 0.1753 Acc: 0.9555\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 0.0240 Acc: 0.9940\n",
      "val Loss: 0.1759 Acc: 0.9474\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 0.0270 Acc: 0.9933\n",
      "val Loss: 0.1720 Acc: 0.9595\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 0.0221 Acc: 0.9944\n",
      "val Loss: 0.1789 Acc: 0.9514\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 0.0252 Acc: 0.9942\n",
      "val Loss: 0.1549 Acc: 0.9555\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 0.0247 Acc: 0.9946\n",
      "val Loss: 0.1603 Acc: 0.9555\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 0.0212 Acc: 0.9959\n",
      "val Loss: 0.1620 Acc: 0.9555\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 0.0229 Acc: 0.9953\n",
      "val Loss: 0.1539 Acc: 0.9555\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 0.0202 Acc: 0.9951\n",
      "val Loss: 0.1651 Acc: 0.9474\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 0.0252 Acc: 0.9948\n",
      "val Loss: 0.1492 Acc: 0.9474\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 0.0255 Acc: 0.9948\n",
      "val Loss: 0.1761 Acc: 0.9514\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 0.0231 Acc: 0.9946\n",
      "val Loss: 0.1607 Acc: 0.9514\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 0.0257 Acc: 0.9940\n",
      "val Loss: 0.1702 Acc: 0.9514\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 0.0264 Acc: 0.9951\n",
      "val Loss: 0.1464 Acc: 0.9555\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 0.0239 Acc: 0.9944\n",
      "val Loss: 0.1792 Acc: 0.9555\n",
      "\n",
      "Training complete in 112m 28s\n",
      "Best val Acc: 0.959514\n"
     ]
    }
   ],
   "source": [
    "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
    "                         exp_lr_scheduler, writer, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
